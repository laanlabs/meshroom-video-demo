{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import cv2\n",
    "import re\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "from skimage.io import imread, imsave\n",
    "from PIL import Image\n",
    "import shutil \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_meshroom(frames_path, output_path, meshroom_base, run_meshing=False):\n",
    "    \n",
    "    if not os.path.exists(meshroom_base):\n",
    "        print(\"Could not find meshroom base path ( where you downloaded to ) \")\n",
    "        return\n",
    "\n",
    "    #path = os.path.abspath(__file__)\n",
    "    #base = os.path.dirname(path)\n",
    "\n",
    "    graph_name = \"meshroom_graph_all.mg\"\n",
    "    \n",
    "    if run_meshing == False:\n",
    "        graph_name = \"meshroom_graph_no_mesh.mg\"\n",
    "\n",
    "    graph_path = graph_name #os.path.join(base, graph_name)\n",
    "\n",
    "    assert os.path.exists(graph_path), \"Could not find meshroom graph file\"\n",
    "\n",
    "    frames_path = os.path.abspath(frames_path)\n",
    "    output_path = os.path.abspath(output_path)\n",
    "    \n",
    "    exe_path = os.path.join(meshroom_base, \"meshroom_photogrammetry.exe\")\n",
    "\n",
    "    kwargs = {\n",
    "        \"exe_path\" : exe_path,\n",
    "        \"input\" : frames_path,\n",
    "        \"cache\" : output_path, \n",
    "        \"output\" : output_path,\n",
    "        \"pipeline\" : graph_path,\n",
    "    }\n",
    "\n",
    "    cmd = \"{exe_path} --input {input} --cache {cache} --pipeline {pipeline} --output {output}\".format(**kwargs)\n",
    "    print(\"[Meshroom] Running cmd: \", cmd)\n",
    "\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def copy_meshroom_files_and_cleanup(meshroom_base, to_path):\n",
    "\n",
    "    sfm_path = os.path.join(meshroom_base, \"StructureFromMotion\")\n",
    "\n",
    "    if not os.path.exists(sfm_path):\n",
    "        print(\"Couldnt find MeshroomCache folder - meshroom/StructureFromMotion \")\n",
    "        return\n",
    "\n",
    "    def SubDirPath (d):\n",
    "        return filter(os.path.isdir, [os.path.join(d,f) for f in os.listdir(d)])\n",
    "\n",
    "    def LatestDirectory (d):\n",
    "        return max(SubDirPath(d), key=os.path.getmtime)\n",
    "\n",
    "    \n",
    "    cameras_path = os.path.join(LatestDirectory(sfm_path), \"cameras.sfm\")\n",
    "    cloud_path = os.path.join(LatestDirectory(sfm_path), \"cloud_and_poses.abc\")\n",
    "\n",
    "    export_path = os.path.join(meshroom_base, \"ExportAnimatedCamera\")\n",
    "    undist_images_path = os.path.join(LatestDirectory(export_path), \"undistort\")\n",
    "\n",
    "\n",
    "    if not os.path.exists(cameras_path):\n",
    "        print(\"Couldnt find cameras.sfm - /StructureFromMotion/UUID/cameras.sfm \")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(undist_images_path):\n",
    "        print(\"Couldnt find undistorted images folder - ExportAnimatedCamera/UUID/undistort\")\n",
    "        return\n",
    "\n",
    "\n",
    "    try:\n",
    "        #ConvertSfMFormat / sfm.json\n",
    "        convert_path = os.path.join(meshroom_base, \"ConvertSfMFormat\")\n",
    "        sfm_json_path = os.path.join(LatestDirectory(convert_path), \"sfm.json\")\n",
    "        shutil.copy2( sfm_json_path, to_path )\n",
    "    except Exception as e:\n",
    "        print(\"Error copying sfm data: \", str(e))\n",
    "    \n",
    "    # Texturing optional\n",
    "    texturing_base = os.path.join(meshroom_base, \"Texturing\")\n",
    "    if os.path.exists(texturing_base):\n",
    "        texturing_base = LatestDirectory(texturing_base)\n",
    "        # Copy textured .obj file \n",
    "        files = [\"texturedMesh.obj\", \"texturedMesh.mtl\"]\n",
    "        for file in files:\n",
    "            tex_path = os.path.join(texturing_base, file)\n",
    "            if os.path.exists( tex_path ):\n",
    "                shutil.copy2( tex_path, to_path)\n",
    "            else:\n",
    "                print(\" [Warning] Could not find mesh file: \", file )\n",
    "\n",
    "        textures = glob.glob( os.path.join(texturing_base, \"*.png\") )\n",
    "        textures += glob.glob( os.path.join(texturing_base, \"*.jpg\") )\n",
    "        \n",
    "        for tex_file in textures:\n",
    "            shutil.copy2( tex_file, to_path )\n",
    "\n",
    "\n",
    "    shutil.copy2( cameras_path, to_path )\n",
    "\n",
    "    if os.path.exists(cloud_path):\n",
    "        shutil.copy2( cloud_path, to_path )\n",
    "\n",
    "    try:\n",
    "        shutil.copytree(undist_images_path, os.path.join(to_path, \"undistorted_frames\"))\n",
    "    except Exception as e:\n",
    "        print(\"Error copying undistorted frames: \\n\", str(e))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_video_frames_gen(video_path):\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    while True:\n",
    "        read_flag, frame = capture.read()\n",
    "        if not read_flag:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        yield frame\n",
    "\n",
    "    capture.release()\n",
    "\n",
    "    \n",
    "def extract_frames(video_path, out_path, step=1):\n",
    "    \n",
    "    video_generator = get_video_frames_gen(video_path)\n",
    "    frame_out_idx = 0\n",
    "    \n",
    "    for frame_idx, image_arr in enumerate(video_generator):\n",
    "        if frame_idx % step != 0:\n",
    "            continue\n",
    "        frame_name = \"frame_{:05d}.jpg\".format(frame_out_idx)\n",
    "        frame_out_path = os.path.join(out_path, frame_name)\n",
    "        imsave(frame_out_path, image_arr)\n",
    "        frame_out_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alice_to_gl(pose_in):\n",
    "    pose_out = pose_in.copy()\n",
    "    \n",
    "    # X \n",
    "    pose_out[1,0] = pose_in[0,1]\n",
    "    pose_out[2,0] = pose_in[0,2]\n",
    "    \n",
    "    # Y \n",
    "    pose_out[0,1] = pose_in[1,0] * -1.0\n",
    "    pose_out[1,1] = pose_in[1,1] * -1.0 # flip Y \n",
    "    pose_out[2,1] = pose_in[1,2] * -1.0 \n",
    "    \n",
    "    # Z \n",
    "    pose_out[0,2] = pose_in[2,0] * -1.0\n",
    "    pose_out[1,2] = pose_in[2,1] * -1.0 \n",
    "    pose_out[2,2] = pose_in[2,2] * -1.0\n",
    "    \n",
    "    return pose_out\n",
    "    \n",
    "    \n",
    "def get_pose_mat(p_dict):\n",
    "    trans = p_dict['pose']['transform']\n",
    "    translation = trans['center']\n",
    "    rot = trans['rotation']\n",
    "    mat = np.eye(4, dtype=np.float64)\n",
    "    #mat[:3,:3] = np.array(rot).reshape((3,3))\n",
    "    mat[:3, 0] = rot[0:3]\n",
    "    mat[:3, 1] = rot[3:6]\n",
    "    mat[:3, 2] = rot[6:9]\n",
    "    mat[:3, 3] = translation \n",
    "    return mat\n",
    "\n",
    "def convert_rt_to_opengl(rvec, tvec):\n",
    "    # https://answers.opencv.org/question/23089/opencv-opengl-proper-camera-pose-using-solvepnp/\n",
    "    \n",
    "    view_matrix = np.zeros((4,4), np.float32)\n",
    "    rvec = rvec.astype(np.float32)\n",
    "    assert rvec.shape[0] == 3\n",
    "\n",
    "    rotation, jacobian = cv2.Rodrigues(rvec)\n",
    "    \n",
    "    view_matrix[:3,:3] = rotation\n",
    "    view_matrix[:3, 3] = tvec[:,0]\n",
    "    view_matrix[3,3] = 1.0\n",
    "    \n",
    "    view_matrix = np.linalg.inv(view_matrix)\n",
    "    view_matrix[:,1] *= -1.0\n",
    "    view_matrix[:,2] *= -1.0\n",
    "    \n",
    "    return view_matrix \n",
    "\n",
    "\n",
    "def get_projection_matrix(width, height, yfov_radians, znear=0.01, zfar=1000.0):\n",
    "    \"\"\"Return the OpenGL projection matrix for this camera.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width : int\n",
    "        Width of the current viewport, in pixels.\n",
    "    height : int\n",
    "        Height of the current viewport, in pixels.\n",
    "    \"\"\"\n",
    "\n",
    "    aspect_ratio = float(width) / float(height)\n",
    "\n",
    "    a = aspect_ratio\n",
    "    t = np.tan(yfov_radians / 2.0)\n",
    "    n = znear\n",
    "    f = zfar\n",
    "\n",
    "    P = np.zeros((4,4))\n",
    "    P[0][0] = 1.0 / (a * t)\n",
    "    P[1][1] = 1.0 / t\n",
    "    P[3][2] = -1.0\n",
    "\n",
    "    if f is None:\n",
    "        P[2][2] = -1.0\n",
    "        P[2][3] = -2.0 * n\n",
    "    else:\n",
    "        P[2][2] = (f + n) / (n - f)\n",
    "        P[2][3] = (2 * f * n) / (n - f)\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Meshroom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshroom_exe_base_path = \"D:\\\\Meshroom-2019.1.0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"IMG_6097.MOV\"\n",
    "frame_step = 8\n",
    "run_meshing = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name, ext = os.path.splitext(os.path.basename(video_path))\n",
    "video_base = os.path.dirname(video_path)\n",
    "video_data_path = os.path.join(video_base, video_name + \"_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This takes a while \n",
    "#### NOTE: even if 'run_meshing' is True, this step can still fail to generate a mesh\n",
    "This happens when certain images aren't processed \n",
    "\n",
    "#### NOTE:  delete any existing output if running this multiple times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_out_path = os.path.join(video_data_path, \"frames\")\n",
    "\n",
    "os.makedirs(frames_out_path)\n",
    "\n",
    "print(\" [Extracting Frames] \", video_path , frames_out_path)\n",
    "\n",
    "extract_frames(video_path, frames_out_path, step=frame_step)\n",
    "\n",
    "meshroom_path = os.path.join(video_data_path, \"meshroom\")\n",
    "\n",
    "\n",
    "os.makedirs(meshroom_path)\n",
    "\n",
    "\n",
    "run_meshroom(frames_out_path, meshroom_path, \n",
    "             meshroom_base=meshroom_exe_base_path, \n",
    "             run_meshing=run_meshing)\n",
    "\n",
    "\n",
    "copy_meshroom_files_and_cleanup(meshroom_path, video_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_poses = json.load(open( os.path.join( video_data_path , \"cameras.sfm\") , 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "undist_base = os.path.join(video_data_path, \"undistorted_frames\")\n",
    "undist_images = sorted(glob.glob(os.path.join(undist_base, \"*.jpg\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(undist_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_file = os.path.join(video_data_path, \"texturedMesh.obj\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_scene = trimesh.load(obj_file)\n",
    "# this used to return Trimesh ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obj_scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(obj_scene, trimesh.Trimesh):\n",
    "    meshes = [obj_scene]\n",
    "else:\n",
    "    meshes = [ v for k,v in obj_scene.geometry.items() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_mesh = pyrender.Mesh.from_trimesh(meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_mesh.primitives[0].material.doubleSided = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = camera_poses['views']\n",
    "pose_dicts = camera_poses['poses']\n",
    "intrinsics = camera_poses['intrinsics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w = int(intrinsics[0]['width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px,py = map(float, intrinsics[0]['principalPoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length = float(intrinsics[0]['pxFocalLength'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h, img_w = image.shape[:2]\n",
    "print(img_w, img_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfov_radians = 2.0 * arctan( (img_h / 2.0) / focal_length )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_for_image(image_name, views):\n",
    "    view = None \n",
    "    for v in views:\n",
    "        if os.path.basename(v['path']) == image_name:\n",
    "            return v\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_poses = {}\n",
    "id_to_pose_dict = {}\n",
    "for p in pose_dicts:\n",
    "    pose_id = p['poseId']\n",
    "    id_to_poses[pose_id] = get_pose_mat(p)\n",
    "    id_to_pose_dict[pose_id] = p.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Render 3d Mesh overlaid onto images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = pyrender.Scene(ambient_light=[1.15, 1.15, 1.15],\n",
    "                       bg_color=[0.0, 0.0, 0.0])\n",
    "\n",
    "camera = pyrender.PerspectiveCamera(yfov = yfov_radians)\n",
    "\n",
    "camera_node = pyrender.Node(camera=camera, matrix=np.eye(4))\n",
    "scene.add_node(camera_node)\n",
    "\n",
    "scene.add(obj_mesh)\n",
    "\n",
    "light = pyrender.PointLight(intensity=1.3)\n",
    "scene.add(light, pose=np.eye(4))\n",
    "\n",
    "renderer = pyrender.OffscreenRenderer(img_w, img_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mat = obj_mesh.primitives[0].material\n",
    "mat.wireframe = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.baseColorFactor = np.array([1,1,1,1], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_out_path = os.path.join(video_data_path, \"viz.mp4\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "video_out = cv2.VideoWriter(video_out_path, fourcc, 24.0, (img_w, img_h))\n",
    "\n",
    "num_frames = len(undist_images)\n",
    "\n",
    "depth_alpha = None\n",
    "\n",
    "\n",
    "for i, undist_path in tqdm(enumerate(undist_images), total=num_frames):\n",
    "    \n",
    "    undist_image_name = os.path.basename(undist_path)    \n",
    "    input_image = imread(undist_path)\n",
    "    \n",
    "    #print(undist_image_name)\n",
    "    \n",
    "    # These are named 1342558130_frame_000001.jpg hopefully that's consistent \n",
    "    image_name = re.findall(r'(\\d+)_(.*)', undist_image_name)[0][1]\n",
    "    \n",
    "    view = view_for_image(image_name, views)\n",
    "    pose_id = view['poseId']\n",
    "    \n",
    "    if pose_id not in id_to_poses:\n",
    "        print(\"Missing pose for image: \", image_name)\n",
    "        continue\n",
    "        \n",
    "    pose_alice = id_to_poses[pose_id]\n",
    "    pose_gl = alice_to_gl(pose_alice)\n",
    "    \n",
    "    projection = get_projection_matrix(img_w, img_h, yfov_radians)\n",
    "    view_matrix = np.linalg.inv(pose_gl)\n",
    "    mvp = np.dot(projection, view_matrix)\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    scene.set_pose(camera_node, pose_gl)\n",
    "    color_img, depth = renderer.render(scene)\n",
    "    \n",
    "    #print( \" Depth max: {:5.3f}  min {:5.3f}\".format( depth.min(), depth.max() ))\n",
    "    \n",
    "    max_depth = 0.75\n",
    "    \n",
    "    depth_norm = (255.0 * (depth / max_depth)).astype(np.uint8)\n",
    "    depth_color = cv2.applyColorMap(depth_norm, cv2.COLORMAP_HSV)\n",
    "    \n",
    "    progress = i / float(num_frames-1)\n",
    "    \n",
    "    if depth_alpha is None:\n",
    "        depth_alpha = np.zeros_like(input_image, dtype=np.float)\n",
    "        h,w = input_image.shape[:2]\n",
    "    \n",
    "    depth_alpha.fill(0)\n",
    "    row_end = int(round(  h * np.sin( progress * np.pi * 0.5)))\n",
    "    depth_alpha[:row_end, :, :] = 1.0 \n",
    "        \n",
    "#     depth_alpha = (float(i) / float( min(140,num_frames) ))\n",
    "#     depth_alpha = 0.9 * min(1.0, depth_alpha)\n",
    "#     depth_alpha = (i / float(num_frames)) * 2.0\n",
    "    \n",
    "    output = depth_color.astype(np.float) * depth_alpha + input_image.astype(np.float) * (1.0 - depth_alpha)\n",
    "    \n",
    "    #color_img = cv2.cvtColor(color_img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    video_out.write(  cv2.cvtColor(output.astype(np.uint8), cv2.COLOR_RGB2BGR)  )\n",
    "    \n",
    "    \n",
    "video_out.release() \n",
    "video_out = None \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
